{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2273e787-23cb-4c54-a406-a1f313207ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933a599f-2f54-475e-9acc-cc82b9c911dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_file_columns(file_path, n_rows=5):\n",
    "    \"\"\"\n",
    "    Quickly read the first few rows of a pipe-delimited file\n",
    "    and print cleaned column names.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        delimiter=\"|\",\n",
    "        nrows=n_rows,\n",
    "        dtype=str\n",
    "    )\n",
    "    # Clean columns\n",
    "    df.columns = df.columns.str.strip(\" ~'\")\n",
    "    print(f\"Columns in {file_path}:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52169717-6cf8-4fc1-b850-0220e60e6a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in ../data/raw/FACTPCRPRIMARYIMPRESSION.txt:\n",
      "- PcrKey\n",
      "- eSituation_11\n",
      "Columns in ../data/raw/FACTPCRSECONDARYIMPRESSION.txt:\n",
      "- PcrKey\n",
      "- eSituation_12\n",
      "Columns in ../data/raw/FACTPCRPRIMARYSYMPTOM.txt:\n",
      "- PcrKey\n",
      "- eSituation_09\n",
      "Columns in ../data/raw/FACTPCRADDITIONALSYMPTOM.txt:\n",
      "- PcrKey\n",
      "- eSituation_10\n",
      "Columns in ../data/raw/FACTPCRCAUSEOFINJURY.txt:\n",
      "- PcrKey\n",
      "- eInjury_01\n",
      "Columns in ../data/raw/FACTPCRINJURYRISKFACTOR.txt:\n",
      "- PcrKey\n",
      "- eInjury_04\n",
      "Columns in ../data/raw/FACTPCRTRAUMACRITERIA.txt:\n",
      "- PcrKey\n",
      "- eInjury_03\n",
      "Columns in ../data/raw/FACTPCRBARRIERTOCARE.txt:\n",
      "- PcrKey\n",
      "- eHistory_01\n",
      "Columns in ../data/raw/FACTPCRDISPATCHDELAY.txt:\n",
      "- PcrKey\n",
      "- eResponse_08\n",
      "Columns in ../data/raw/FACTPCRRESPONSEDELAY.txt:\n",
      "- PcrKey\n",
      "- eResponse_09\n",
      "Columns in ../data/raw/FACTPCRSCENEDELAY.txt:\n",
      "- PcrKey\n",
      "- eResponse_10\n",
      "Columns in ../data/raw/FACTPCRTRANSPORTDELAY.txt:\n",
      "- PcrKey\n",
      "- eResponse_11\n",
      "Columns in ../data/raw/FACTPCRTURNAROUNDDELAY.txt:\n",
      "- PcrKey\n",
      "- eResponse_12\n",
      "Columns in ../data/raw/FACTPCRDESTINATIONREASON.txt:\n",
      "- PcrKey\n",
      "- eDisposition_20\n",
      "Columns in ../data/raw/FACTPCRDESTINATIONTEAM.txt:\n",
      "- eDisposition_25\n",
      "- PcrKey\n",
      "- eDisposition_24\n",
      "Columns in ../data/raw/FACTPCRVITAL.txt:\n",
      "- PcrVitalKey\n",
      "- PcrKey\n",
      "- eVitals_06\n",
      "- eVitals_10\n",
      "- eVitals_12\n",
      "- eVitals_14\n",
      "- eVitals_16\n",
      "- eVitals_18\n",
      "- eVitals_27\n",
      "- eVitals_02\n",
      "- eVitals_04\n",
      "- eVitals_08\n",
      "- eVitals_26\n",
      "- eVitals_29\n",
      "- eVitals_30\n",
      "- eVitals_31\n",
      "- eVitals_19\n",
      "- eVitals_20\n",
      "- eVitals_21\n",
      "- eVitals_01\n",
      "Columns in ../data/raw/FACTPCRARRESTCPRPROVIDED.txt:\n",
      "- PcrKey\n",
      "- eArrest_09\n",
      "Columns in ../data/raw/FACTPCRARRESTRESUSCITATION.txt:\n",
      "- PcrKey\n",
      "- eArrest_03\n",
      "Columns in ../data/raw/FACTPCRARRESTRHYTHMDESTINATION.txt:\n",
      "- PcrKey\n",
      "- eArrest_17\n",
      "Columns in ../data/raw/FACTPCRARRESTROSC.txt:\n",
      "- PcrKey\n",
      "- eArrest_12\n",
      "Columns in ../data/raw/FACTPCRARRESTWITNESS.txt:\n",
      "- PcrKey\n",
      "- eArrest_04\n",
      "Columns in ../data/raw/FACTPCRMEDICATION.txt:\n",
      "- eMedications_01\n",
      "- PcrMedicationKey\n",
      "- PcrKey\n",
      "- eMedications_03\n",
      "- eMedications_03Descr\n",
      "- eMedications_05\n",
      "- eMedications_06\n",
      "- eMedications_07\n",
      "- eMedications_10\n",
      "- eMedications_02\n",
      "Columns in ../data/raw/FACTPCRPROCEDURE.txt:\n",
      "- PcrProcedureKey\n",
      "- PcrKey\n",
      "- eProcedures_03\n",
      "- eProcedures_05\n",
      "- eProcedures_06\n",
      "- eProcedures_08\n",
      "- eProcedures_10\n",
      "- eProcedures_02\n",
      "- eProcedures_01\n",
      "Columns in ../data/raw/FACTPCRPROTOCOL.txt:\n",
      "- PcrKey\n",
      "- eProtocols_01\n",
      "- eProtocols_02\n",
      "Columns in ../data/raw/FACTPCRADDITIONALRESPONSEMODE.txt:\n",
      "- PcrKey\n",
      "- eResponse_24\n",
      "Columns in ../data/raw/FACTPCRADDITIONALTRANSPORTMODE.txt:\n",
      "- PcrKey\n",
      "- eDisposition_18\n",
      "Columns in ../data/raw/FACTPCRALCOHOLDRUGUSEINDICATOR.txt:\n",
      "- PcrKey\n",
      "- eHistory_17\n",
      "Columns in ../data/raw/FACTPCRWORKRELATEDEXPOSURE.txt:\n",
      "- PcrKey\n",
      "- eOther_05\n",
      "Columns in ../data/raw/PCRPATIENTRACEGROUP.txt:\n",
      "- PcrPatientRaceGroupKey\n",
      "- PcrKey\n",
      "- ePatient_14\n",
      "Columns in ../data/raw/PCRPROCCOMPGROUP.txt:\n",
      "- PcrProcCompGroupKey\n",
      "- ProcedureKey\n",
      "- eProcedures_07\n",
      "Columns in ../data/raw/PCRMEDCOMPGROUP.txt:\n",
      "- PcrMedCompGroupKey\n",
      "- MedicationKey\n",
      "- eMedications_08\n",
      "Columns in ../data/raw/PCRVITALECGGROUP.txt:\n",
      "- PcrVitalECGGroupKey\n",
      "- VitalKey\n",
      "- eVitals_03\n",
      "Columns in ../data/raw/PCRVITALECGINTERPRETATIONGROUP.txt:\n",
      "- PcrVitalECGInterpretationGroupKe\n",
      "- VitalKey\n",
      "- eVitals_05\n",
      "Columns in ../data/raw/PCRVITALGLASGOWQUALIFIERGROUP.txt:\n",
      "- PcrVitalECGGroupKey\n",
      "- VitalKey\n",
      "- eVitals_22\n",
      "Columns in ../data/raw/pub_pcrevents_cp25.txt:\n",
      "- PcrKey\n",
      "- eDispatch_01\n",
      "- eDispatch_02\n",
      "- eArrest_14\n",
      "- eArrest_01\n",
      "- eArrest_02\n",
      "- eArrest_05\n",
      "- eArrest_07\n",
      "- eArrest_11\n",
      "- eArrest_16\n",
      "- eArrest_18\n",
      "- eDisposition_12\n",
      "- eDisposition_19\n",
      "- eDisposition_16\n",
      "- eDisposition_21\n",
      "- eDisposition_22\n",
      "- eDisposition_23\n",
      "- eOutcome_01\n",
      "- eOutcome_02\n",
      "- ePatient_15\n",
      "- ePatient_16\n",
      "- ePayment_01\n",
      "- ePayment_50\n",
      "- eResponse_05\n",
      "- eResponse_07\n",
      "- eResponse_15\n",
      "- eResponse_23\n",
      "- eScene_01\n",
      "- eScene_06\n",
      "- eScene_07\n",
      "- eScene_08\n",
      "- eScene_09\n",
      "- eSituation_02\n",
      "- eSituation_07\n",
      "- eSituation_08\n",
      "- eSituation_13\n",
      "- eSituation_01\n",
      "- eTimes_01\n",
      "- eTimes_03\n",
      "- eTimes_05\n",
      "- eTimes_06\n",
      "- eTimes_07\n",
      "- eTimes_09\n",
      "- eTimes_11\n",
      "- eTimes_12\n",
      "- eTimes_13\n",
      "- eDisposition_17\n"
     ]
    }
   ],
   "source": [
    "# Provider Impressions\n",
    "inspect_file_columns(\"../data/raw/FACTPCRPRIMARYIMPRESSION.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRSECONDARYIMPRESSION.txt\")\n",
    "\n",
    "# Symptoms\n",
    "inspect_file_columns(\"../data/raw/FACTPCRPRIMARYSYMPTOM.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRADDITIONALSYMPTOM.txt\")\n",
    "\n",
    "# Cause of Injury and Trauma\n",
    "inspect_file_columns(\"../data/raw/FACTPCRCAUSEOFINJURY.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRINJURYRISKFACTOR.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRTRAUMACRITERIA.txt\")\n",
    "\n",
    "# Barriers to Care\n",
    "inspect_file_columns(\"../data/raw/FACTPCRBARRIERTOCARE.txt\")\n",
    "\n",
    "# Delay Types\n",
    "inspect_file_columns(\"../data/raw/FACTPCRDISPATCHDELAY.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRRESPONSEDELAY.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRSCENEDELAY.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRTRANSPORTDELAY.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRTURNAROUNDDELAY.txt\")\n",
    "\n",
    "# Destination Details\n",
    "inspect_file_columns(\"../data/raw/FACTPCRDESTINATIONREASON.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRDESTINATIONTEAM.txt\")\n",
    "\n",
    "# Vitals\n",
    "inspect_file_columns(\"../data/raw/FACTPCRVITAL.txt\")\n",
    "\n",
    "# Arrest & CPR\n",
    "inspect_file_columns(\"../data/raw/FACTPCRARRESTCPRPROVIDED.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRARRESTRESUSCITATION.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRARRESTRHYTHMDESTINATION.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRARRESTROSC.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRARRESTWITNESS.txt\")\n",
    "\n",
    "# Medication & Procedure\n",
    "inspect_file_columns(\"../data/raw/FACTPCRMEDICATION.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRPROCEDURE.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRPROTOCOL.txt\")\n",
    "\n",
    "# Additional Modes\n",
    "inspect_file_columns(\"../data/raw/FACTPCRADDITIONALRESPONSEMODE.txt\")\n",
    "inspect_file_columns(\"../data/raw/FACTPCRADDITIONALTRANSPORTMODE.txt\")\n",
    "\n",
    "# Alcohol/Drug Use Indicator\n",
    "inspect_file_columns(\"../data/raw/FACTPCRALCOHOLDRUGUSEINDICATOR.txt\")\n",
    "\n",
    "# Work Related Exposure\n",
    "inspect_file_columns(\"../data/raw/FACTPCRWORKRELATEDEXPOSURE.txt\")\n",
    "\n",
    "# Patient Groupings\n",
    "inspect_file_columns(\"../data/raw/PCRPATIENTRACEGROUP.txt\")\n",
    "\n",
    "# Procedure/ECG Groupings\n",
    "inspect_file_columns(\"../data/raw/PCRPROCCOMPGROUP.txt\")\n",
    "inspect_file_columns(\"../data/raw/PCRMEDCOMPGROUP.txt\")\n",
    "inspect_file_columns(\"../data/raw/PCRVITALECGGROUP.txt\")\n",
    "inspect_file_columns(\"../data/raw/PCRVITALECGINTERPRETATIONGROUP.txt\")\n",
    "inspect_file_columns(\"../data/raw/PCRVITALGLASGOWQUALIFIERGROUP.txt\")\n",
    "\n",
    "# Core Events Table\n",
    "inspect_file_columns(\"../data/raw/pub_pcrevents_cp25.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67456394-cd26-41fc-af0b-399bd364463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Primary Impressions: 530it [00:21, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary impressions matched: 231354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define target ICD-10 prefixes\n",
    "target_prefixes = (\"T40\", \"F11\")\n",
    "\n",
    "# Path to primary impressions file\n",
    "primary_path = \"../data/raw/FACTPCRPRIMARYIMPRESSION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "primary_chunks = []\n",
    "\n",
    "with open(primary_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Primary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_11\"] = chunk[\"eSituation_11\"].str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_11\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk.loc[mask, [\"PcrKey\"]]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            primary_chunks.append(filtered)\n",
    "\n",
    "primary_df = pd.concat(primary_chunks, ignore_index=True)\n",
    "print(\"Primary impressions matched:\", len(primary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42d367fc-6922-4a93-8705-3648ae4a8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Secondary Impressions: 544it [00:22, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary impressions matched: 42853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to secondary impressions file\n",
    "secondary_path = \"../data/raw/FACTPCRSECONDARYIMPRESSION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "secondary_chunks = []\n",
    "\n",
    "with open(secondary_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Secondary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_12\"] = chunk[\"eSituation_12\"].str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_12\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk.loc[mask, [\"PcrKey\"]]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            secondary_chunks.append(filtered)\n",
    "\n",
    "secondary_df = pd.concat(secondary_chunks, ignore_index=True)\n",
    "print(\"Secondary impressions matched:\", len(secondary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5698a695-cf23-40a5-8e95-f78d438841b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique opioid-related cases: 271206\n"
     ]
    }
   ],
   "source": [
    "# Combine and deduplicate primary and secondary impression matches\n",
    "opioid_cases = pd.concat([primary_df, secondary_df], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Optionally, turn it into a set for fast lookups\n",
    "opioid_pcr_keys = set(opioid_cases[\"PcrKey\"])\n",
    "print(\"Total unique opioid-related cases:\", len(opioid_pcr_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8ab3cf-ba62-48ad-b502-cc28fef66b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering pub_pcrevents_cp25.txt: 542it [04:28,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered events records: 271206\n"
     ]
    }
   ],
   "source": [
    "# Load core events table\n",
    "events_path = \"../data/raw/pub_pcrevents_cp25.txt\"\n",
    "events_chunks = []\n",
    "\n",
    "with open(events_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Filtering pub_pcrevents_cp25.txt\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "        if not filtered.empty:\n",
    "            events_chunks.append(filtered)\n",
    "\n",
    "events_df = pd.concat(events_chunks, ignore_index=True)\n",
    "print(\"Filtered events records:\", len(events_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "560eeb85-996c-4e9d-ad35-51a3155a80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Primary Symptom: 534it [00:37, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged primary symptom. New shape: (271206, 48)\n"
     ]
    }
   ],
   "source": [
    "# Load and aggregate eSituation_09 (Primary Symptom)\n",
    "symptom_path = \"../data/raw/FACTPCRPRIMARYSYMPTOM.txt\"\n",
    "symptom_chunks = []\n",
    "\n",
    "with open(symptom_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Primary Symptom\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "        chunk[\"eSituation_09\"] = chunk[\"eSituation_09\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "        if not filtered.empty:\n",
    "            symptom_chunks.append(filtered[[\"PcrKey\", \"eSituation_09\"]])\n",
    "\n",
    "symptom_df = pd.concat(symptom_chunks, ignore_index=True)\n",
    "\n",
    "# Merge into events_df (one-to-one)\n",
    "events_df = events_df.merge(symptom_df, on=\"PcrKey\", how=\"left\")\n",
    "print(\"Merged primary symptom. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9dc00fd-81aa-4309-8fb2-43518e603bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Associated Symptoms: 580it [00:41, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged associated symptoms. New shape: (271206, 50)\n"
     ]
    }
   ],
   "source": [
    "# Load and aggregate eSituation_10 (Other Associated Symptoms)\n",
    "assoc_path = \"../data/raw/FACTPCRADDITIONALSYMPTOM.txt\"\n",
    "assoc_chunks = []\n",
    "\n",
    "with open(assoc_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Associated Symptoms\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "        chunk[\"eSituation_10\"] = chunk[\"eSituation_10\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "        if not filtered.empty:\n",
    "            assoc_chunks.append(filtered[[\"PcrKey\", \"eSituation_10\"]])\n",
    "\n",
    "assoc_df = pd.concat(assoc_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate: count and nunique per PcrKey\n",
    "assoc_agg = (\n",
    "    assoc_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        assoc_symptom_count=(\"eSituation_10\", \"count\"),\n",
    "        assoc_symptom_unique=(\"eSituation_10\", \"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge\n",
    "events_df = events_df.merge(assoc_agg, on=\"PcrKey\", how=\"left\")\n",
    "print(\"Merged associated symptoms. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d332e356-700b-493b-94e7-04ebaf646b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reloading Primary Impressions: 530it [00:36, 14.59it/s]\n",
      "Reloading Secondary Impressions: 544it [00:38, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged primary impression. New shape: (271206, 51)\n",
      "Merged secondary impression. New shape: (281813, 52)\n"
     ]
    }
   ],
   "source": [
    "# Reload and merge full Primary and Secondary Impressions\n",
    "\n",
    "primary_chunks = []\n",
    "secondary_chunks = []\n",
    "\n",
    "# Reload Primary Impressions\n",
    "with open(\"../data/raw/FACTPCRPRIMARYIMPRESSION.txt\", \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Reloading Primary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "        chunk[\"eSituation_11\"] = chunk[\"eSituation_11\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "        if not filtered.empty:\n",
    "            primary_chunks.append(filtered[[\"PcrKey\", \"eSituation_11\"]])\n",
    "\n",
    "# Reload Secondary Impressions\n",
    "with open(\"../data/raw/FACTPCRSECONDARYIMPRESSION.txt\", \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Reloading Secondary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "        chunk[\"eSituation_12\"] = chunk[\"eSituation_12\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "        if not filtered.empty:\n",
    "            secondary_chunks.append(filtered[[\"PcrKey\", \"eSituation_12\"]])\n",
    "\n",
    "# Concatenate and merge\n",
    "primary_imp_df = pd.concat(primary_chunks, ignore_index=True)\n",
    "secondary_imp_df = pd.concat(secondary_chunks, ignore_index=True)\n",
    "\n",
    "events_df = events_df.merge(primary_imp_df, on=\"PcrKey\", how=\"left\")\n",
    "print(\"Merged primary impression. New shape:\", events_df.shape)\n",
    "\n",
    "events_df = events_df.merge(secondary_imp_df, on=\"PcrKey\", how=\"left\")\n",
    "print(\"Merged secondary impression. New shape:\", events_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e977938-3ff3-4699-a96d-512892d42974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eInjury_01 (Cause of Injury): 545it [00:19, 28.21it/s]\n",
      "Loading eInjury_04 (Risk Factor): 543it [00:18, 28.80it/s]\n",
      "Loading eInjury_03 (Trauma Criteria): 543it [00:18, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injury-related features merged. New shape: (281813, 55)\n"
     ]
    }
   ],
   "source": [
    "# Loading Injury Data\n",
    "\n",
    "# Paths to source files\n",
    "cause_path = \"../data/raw/FACTPCRCAUSEOFINJURY.txt\"\n",
    "risk_path = \"../data/raw/FACTPCRINJURYRISKFACTOR.txt\"\n",
    "trauma_path = \"../data/raw/FACTPCRTRAUMACRITERIA.txt\"\n",
    "\n",
    "# Initialize lists\n",
    "cause_chunks = []\n",
    "risk_chunks = []\n",
    "trauma_chunks = []\n",
    "\n",
    "# Load Cause of Injury (eInjury_01)\n",
    "with open(cause_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eInjury_01 (Cause of Injury)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eInjury_01\"] = chunk[\"eInjury_01\"].str.strip(\" ~'\")\n",
    "        cause_chunks.append(chunk[[\"PcrKey\", \"eInjury_01\"]])\n",
    "\n",
    "cause_df = pd.concat(cause_chunks, ignore_index=True)\n",
    "\n",
    "# Load Injury Risk Factor (eInjury_04)\n",
    "with open(risk_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eInjury_04 (Risk Factor)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eInjury_04\"] = chunk[\"eInjury_04\"].str.strip(\" ~'\")\n",
    "        risk_chunks.append(chunk[[\"PcrKey\", \"eInjury_04\"]])\n",
    "\n",
    "risk_df = pd.concat(risk_chunks, ignore_index=True)\n",
    "\n",
    "# Load Trauma Criteria (eInjury_03)\n",
    "with open(trauma_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eInjury_03 (Trauma Criteria)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eInjury_03\"] = chunk[\"eInjury_03\"].str.strip(\" ~'\")\n",
    "        trauma_chunks.append(chunk[[\"PcrKey\", \"eInjury_03\"]])\n",
    "\n",
    "trauma_df = pd.concat(trauma_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate each to 1 row per PcrKey\n",
    "cause_agg = cause_df.groupby(\"PcrKey\").agg(\n",
    "    injury_cause_count=(\"eInjury_01\", \"nunique\")\n",
    ").reset_index()\n",
    "\n",
    "risk_agg = (\n",
    "    risk_df.dropna(subset=[\"eInjury_04\"])\n",
    "    .groupby(\"PcrKey\")\n",
    "    .size()\n",
    "    .reset_index(name=\"injury_risk_flag\")\n",
    ")\n",
    "risk_agg[\"injury_risk_flag\"] = 1  # presence = 1\n",
    "\n",
    "trauma_agg = trauma_df.groupby(\"PcrKey\").agg(\n",
    "    trauma_criteria_count=(\"eInjury_03\", \"nunique\")\n",
    ").reset_index()\n",
    "\n",
    "# Merge into events_df\n",
    "events_df = events_df.merge(cause_agg, on=\"PcrKey\", how=\"left\")\n",
    "events_df = events_df.merge(risk_agg, on=\"PcrKey\", how=\"left\")\n",
    "events_df = events_df.merge(trauma_agg, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "# Fill missing with 0\n",
    "events_df[\"injury_cause_count\"] = events_df[\"injury_cause_count\"].fillna(0).astype(int)\n",
    "events_df[\"injury_risk_flag\"] = events_df[\"injury_risk_flag\"].fillna(0).astype(int)\n",
    "events_df[\"trauma_criteria_count\"] = events_df[\"trauma_criteria_count\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Injury-related features merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a0d8baa-e70a-43f0-8710-8b82782a5986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eHistory_01 (Barriers to Care): 550it [00:37, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barriers to care merged. New shape: (281813, 58)\n"
     ]
    }
   ],
   "source": [
    "# Load and process eHistory_01 (Barriers to Patient Care)\n",
    "barrier_path = \"../data/raw/FACTPCRBARRIERTOCARE.txt\"\n",
    "barrier_chunks = []\n",
    "\n",
    "with open(barrier_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eHistory_01 (Barriers to Care)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eHistory_01\"] = chunk[\"eHistory_01\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            barrier_chunks.append(filtered[[\"PcrKey\", \"eHistory_01\"]])\n",
    "\n",
    "barrier_df = pd.concat(barrier_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate\n",
    "barrier_agg = (\n",
    "    barrier_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        barrier_count=(\"eHistory_01\", \"count\"),\n",
    "        barrier_unique=(\"eHistory_01\", \"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "barrier_agg[\"barrier_present\"] = 1\n",
    "\n",
    "# Merge into main dataset\n",
    "events_df = events_df.merge(barrier_agg, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "# Fill NA with zeros\n",
    "events_df[\"barrier_count\"] = events_df[\"barrier_count\"].fillna(0).astype(int)\n",
    "events_df[\"barrier_unique\"] = events_df[\"barrier_unique\"].fillna(0).astype(int)\n",
    "events_df[\"barrier_present\"] = events_df[\"barrier_present\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Barriers to care merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59f0e6e5-d506-4917-b09e-e9fb8649afaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eResponse_08 from ../data/raw/FACTPCRDISPATCHDELAY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eResponse_08: 543it [00:40, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eResponse_09 from ../data/raw/FACTPCRRESPONSEDELAY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eResponse_09: 545it [00:41, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eResponse_10 from ../data/raw/FACTPCRSCENEDELAY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eResponse_10: 546it [00:40, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eResponse_11 from ../data/raw/FACTPCRTRANSPORTDELAY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eResponse_11: 544it [00:40, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eResponse_12 from ../data/raw/FACTPCRTURNAROUNDDELAY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eResponse_12: 552it [00:40, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All delay types merged. New shape: (281813, 73)\n"
     ]
    }
   ],
   "source": [
    "# Delay files and their corresponding column names\n",
    "delay_sources = {\n",
    "    \"../data/raw/FACTPCRDISPATCHDELAY.txt\": \"eResponse_08\",\n",
    "    \"../data/raw/FACTPCRRESPONSEDELAY.txt\": \"eResponse_09\",\n",
    "    \"../data/raw/FACTPCRSCENEDELAY.txt\": \"eResponse_10\",\n",
    "    \"../data/raw/FACTPCRTRANSPORTDELAY.txt\": \"eResponse_11\",\n",
    "    \"../data/raw/FACTPCRTURNAROUNDDELAY.txt\": \"eResponse_12\",\n",
    "}\n",
    "\n",
    "# Loop through each and join delay features\n",
    "for file_path, col in delay_sources.items():\n",
    "    print(f\"Processing {col} from {file_path}\")\n",
    "    delay_chunks = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for chunk in tqdm(\n",
    "            pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "            desc=f\"Loading {col}\"\n",
    "        ):\n",
    "            chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "            chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "            chunk[col] = chunk[col].str.strip(\" ~'\")\n",
    "\n",
    "            filtered = chunk[chunk[\"PcrKey\"].isin(opioid_pcr_keys)]\n",
    "            if not filtered.empty:\n",
    "                delay_chunks.append(filtered[[\"PcrKey\", col]])\n",
    "\n",
    "    delay_df = pd.concat(delay_chunks, ignore_index=True)\n",
    "\n",
    "    # Aggregate delay types per PcrKey\n",
    "    delay_agg = (\n",
    "        delay_df.groupby(\"PcrKey\")[col]\n",
    "        .agg([\n",
    "            (\"{}_count\".format(col), \"count\"),\n",
    "            (\"{}_unique\".format(col), \"nunique\")\n",
    "        ])\n",
    "        .reset_index()\n",
    "    )\n",
    "    delay_agg[\"{}_present\".format(col)] = 1\n",
    "\n",
    "    # Merge into main events_df\n",
    "    events_df = events_df.merge(delay_agg, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "    # Fill missing values\n",
    "    events_df[\"{}_count\".format(col)] = events_df[\"{}_count\".format(col)].fillna(0).astype(int)\n",
    "    events_df[\"{}_unique\".format(col)] = events_df[\"{}_unique\".format(col)].fillna(0).astype(int)\n",
    "    events_df[\"{}_present\".format(col)] = events_df[\"{}_present\".format(col)].fillna(0).astype(int)\n",
    "\n",
    "print(\"All delay types merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a467c8ac-5103-4405-b6d3-2f399fbcf17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eDisposition_20 from ../data/raw/FACTPCRDESTINATIONREASON.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eDisposition_20: 582it [00:36, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eDisposition_24 & eDisposition_25 from ../data/raw/FACTPCRDESTINATIONTEAM.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eDisposition_24 & 25: 543it [00:45, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination-related features merged. New shape: (297762, 76)\n"
     ]
    }
   ],
   "source": [
    "# Load Destination Reason and Alert Info\n",
    "\n",
    "# File paths\n",
    "dest_reason_path = \"../data/raw/FACTPCRDESTINATIONREASON.txt\"\n",
    "dest_team_path = \"../data/raw/FACTPCRDESTINATIONTEAM.txt\"\n",
    "\n",
    "# Chunks\n",
    "reason_chunks = []\n",
    "team_chunks = []\n",
    "\n",
    "# eDisposition_20 - Reason for choosing destination\n",
    "print(f\"Processing eDisposition_20 from {dest_reason_path}\")\n",
    "with open(dest_reason_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eDisposition_20\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eDisposition_20\"] = chunk[\"eDisposition_20\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "        if not filtered.empty:\n",
    "            reason_chunks.append(filtered[[\"PcrKey\", \"eDisposition_20\"]])\n",
    "\n",
    "reason_df = pd.concat(reason_chunks, ignore_index=True)\n",
    "\n",
    "\n",
    "# eDisposition_24 and eDisposition_25 - Alert type and timestamp\n",
    "print(f\"Processing eDisposition_24 & eDisposition_25 from {dest_team_path}\")\n",
    "with open(dest_team_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eDisposition_24 & 25\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eDisposition_24\"] = chunk[\"eDisposition_24\"].str.strip(\" ~'\")\n",
    "        chunk[\"eDisposition_25\"] = chunk[\"eDisposition_25\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "        if not filtered.empty:\n",
    "            team_chunks.append(filtered[[\"PcrKey\", \"eDisposition_24\", \"eDisposition_25\"]])\n",
    "\n",
    "team_df = pd.concat(team_chunks, ignore_index=True)\n",
    "\n",
    "# Merge into events_df\n",
    "events_df = events_df.merge(reason_df, on=\"PcrKey\", how=\"left\")\n",
    "events_df = events_df.merge(team_df, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "print(\"Destination-related features merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05e8c89f-2bce-4a9b-a789-f98e17e208c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Vitals: 1648it [04:56,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vitals merged. New shape: (297762, 82)\n"
     ]
    }
   ],
   "source": [
    "# Load and aggregate vitals from FACTPCRVITAL.txt\n",
    "\n",
    "vitals_path = \"../data/raw/FACTPCRVITAL.txt\"\n",
    "vitals_chunks = []\n",
    "\n",
    "# Vital fields of interest and new names\n",
    "vital_fields = {\n",
    "    \"eVitals_10\": \"heart_rate\",\n",
    "    \"eVitals_14\": \"resp_rate\",\n",
    "    \"eVitals_06\": \"systolic_bp\",\n",
    "    \"eVitals_12\": \"spo2\",\n",
    "    \"eVitals_18\": \"bgl\",\n",
    "    \"eVitals_16\": \"etco2\"\n",
    "}\n",
    "\n",
    "with open(vitals_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Vitals\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk = chunk[[\"PcrKey\"] + list(vital_fields.keys())]\n",
    "        chunk = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        vitals_chunks.append(chunk)\n",
    "\n",
    "vitals_df = pd.concat(vitals_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate: take the first non-null value per PcrKey per vital\n",
    "agg_dict = {col: \"first\" for col in vital_fields.keys()}\n",
    "vitals_agg = (\n",
    "    vitals_df.groupby(\"PcrKey\")\n",
    "    .agg(agg_dict)\n",
    "    .rename(columns=vital_fields)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge into main dataset\n",
    "events_df = events_df.merge(vitals_agg, on=\"PcrKey\", how=\"left\")\n",
    "print(\"Vitals merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4c7dc0a-db89-4c29-9950-354a4d1e9b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Medications: 628it [01:49,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medications merged. New shape: (297762, 85)\n"
     ]
    }
   ],
   "source": [
    "# Load and process medication administration data\n",
    "\n",
    "med_path = \"../data/raw/FACTPCRMEDICATION.txt\"\n",
    "med_chunks = []\n",
    "\n",
    "with open(med_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Medications\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eMedications_03\"] = chunk[\"eMedications_03\"].str.strip(\" ~'\")\n",
    "        chunk[\"eMedications_03Descr\"] = chunk[\"eMedications_03Descr\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            med_chunks.append(filtered[[\"PcrKey\", \"eMedications_03\", \"eMedications_03Descr\"]])\n",
    "\n",
    "med_df = pd.concat(med_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate\n",
    "med_agg = (\n",
    "    med_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        any_med_administered=(\"eMedications_03\", lambda x: 1),\n",
    "        med_count=(\"eMedications_03\", \"nunique\"),\n",
    "        naloxone_administered=(\"eMedications_03Descr\", lambda x: int(x.str.contains(\"naloxone|narcan\", case=False, na=False).any()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge\n",
    "events_df = events_df.merge(med_agg, on=\"PcrKey\", how=\"left\")\n",
    "events_df[[\"any_med_administered\", \"med_count\", \"naloxone_administered\"]] = events_df[[\"any_med_administered\", \"med_count\", \"naloxone_administered\"]].fillna(0).astype(int)\n",
    "\n",
    "print(\"Medications merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6140ae72-3ef4-4282-987c-a6bd689c503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Procedures: 934it [01:45,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procedures merged. New shape: (297762, 87)\n"
     ]
    }
   ],
   "source": [
    "# Load and process procedure data\n",
    "\n",
    "proc_path = \"../data/raw/FACTPCRPROCEDURE.txt\"\n",
    "proc_chunks = []\n",
    "\n",
    "with open(proc_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Procedures\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eProcedures_03\"] = chunk[\"eProcedures_03\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            proc_chunks.append(filtered[[\"PcrKey\", \"eProcedures_03\"]])\n",
    "\n",
    "proc_df = pd.concat(proc_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate\n",
    "proc_agg = (\n",
    "    proc_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        any_procedure=(\"eProcedures_03\", lambda x: 1),\n",
    "        proc_count=(\"eProcedures_03\", \"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge\n",
    "events_df = events_df.merge(proc_agg, on=\"PcrKey\", how=\"left\")\n",
    "events_df[[\"any_procedure\", \"proc_count\"]] = events_df[[\"any_procedure\", \"proc_count\"]].fillna(0).astype(int)\n",
    "\n",
    "print(\"Procedures merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d959ab6-2c7a-4f73-bed1-d2686700a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Alcohol/Drug Use Indicator: 553it [00:32, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol/drug use merged. New shape: (297762, 88)\n"
     ]
    }
   ],
   "source": [
    "# Alcohol/Drug Use Indicator\n",
    "\n",
    "alcohol_path = \"../data/raw/FACTPCRALCOHOLDRUGUSEINDICATOR.txt\"\n",
    "alcohol_chunks = []\n",
    "\n",
    "with open(alcohol_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Alcohol/Drug Use Indicator\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eHistory_17\"] = chunk[\"eHistory_17\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            alcohol_chunks.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "if alcohol_chunks:\n",
    "    alcohol_df = pd.concat(alcohol_chunks, ignore_index=True).drop_duplicates()\n",
    "    alcohol_df[\"alcohol_drug_use_flag\"] = 1\n",
    "\n",
    "    events_df = events_df.merge(alcohol_df, on=\"PcrKey\", how=\"left\")\n",
    "else:\n",
    "    events_df[\"alcohol_drug_use_flag\"] = 0  # add column if no matches\n",
    "\n",
    "# Always ensure column exists and is filled\n",
    "if \"alcohol_drug_use_flag\" not in events_df.columns:\n",
    "    events_df[\"alcohol_drug_use_flag\"] = 0\n",
    "else:\n",
    "    events_df[\"alcohol_drug_use_flag\"] = events_df[\"alcohol_drug_use_flag\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Alcohol/drug use merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73e8911b-c8ef-4a71-94df-c88642bac47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Protocols: 556it [00:35, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocols merged. New shape: (297762, 90)\n"
     ]
    }
   ],
   "source": [
    "# Protocols Initiated\n",
    "\n",
    "protocol_path = \"../data/raw/FACTPCRPROTOCOL.txt\"\n",
    "protocol_chunks = []\n",
    "\n",
    "with open(protocol_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Protocols\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eProtocols_01\"] = chunk[\"eProtocols_01\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            protocol_chunks.append(filtered[[\"PcrKey\", \"eProtocols_01\"]])\n",
    "\n",
    "protocol_df = pd.concat(protocol_chunks, ignore_index=True)\n",
    "\n",
    "# Group all protocol codes per PcrKey into comma-separated strings\n",
    "protocol_agg = (\n",
    "    protocol_df.groupby(\"PcrKey\")[\"eProtocols_01\"]\n",
    "    .apply(lambda x: \",\".join(sorted(set(x))))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"eProtocols_01\": \"protocols_used\"})\n",
    ")\n",
    "\n",
    "# Also count how many unique protocols were used\n",
    "protocol_agg[\"protocol_count\"] = protocol_agg[\"protocols_used\"].apply(lambda x: len(x.split(\",\")))\n",
    "\n",
    "events_df = events_df.merge(protocol_agg, on=\"PcrKey\", how=\"left\")\n",
    "events_df[\"protocol_count\"] = events_df[\"protocol_count\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Protocols merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdfc657c-196d-4701-866a-c21831744ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eArrest_04: 542it [00:31, 17.46it/s]\n",
      "Loading eArrest_03: 546it [00:31, 17.58it/s]\n",
      "Loading eArrest_09: 546it [00:30, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrest-related flags merged. New shape: (297762, 93)\n"
     ]
    }
   ],
   "source": [
    "# Arrest-related Flags (Witnessed, Resuscitation, CPR)\n",
    "\n",
    "def load_arrest_flags(file_path, field, flag_name):\n",
    "    chunks = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for chunk in tqdm(\n",
    "            pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "            desc=f\"Loading {field}\"\n",
    "        ):\n",
    "            chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "            chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "            chunk[field] = chunk[field].str.strip(\" ~'\")\n",
    "            filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "            if not filtered.empty:\n",
    "                chunks.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "    if chunks:\n",
    "        df = pd.concat(chunks, ignore_index=True).drop_duplicates()\n",
    "        df[flag_name] = 1\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"PcrKey\", flag_name])\n",
    "\n",
    "arrest_flags = []\n",
    "\n",
    "arrest_flags.append(load_arrest_flags(\"../data/raw/FACTPCRARRESTWITNESS.txt\", \"eArrest_04\", \"arrest_witnessed_flag\"))\n",
    "arrest_flags.append(load_arrest_flags(\"../data/raw/FACTPCRARRESTRESUSCITATION.txt\", \"eArrest_03\", \"resuscitation_flag\"))\n",
    "arrest_flags.append(load_arrest_flags(\"../data/raw/FACTPCRARRESTCPRPROVIDED.txt\", \"eArrest_09\", \"cpr_provided_flag\"))\n",
    "\n",
    "# Merge each into events_df\n",
    "for flag_df in arrest_flags:\n",
    "    events_df = events_df.merge(flag_df, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "# Fill missing with 0\n",
    "for col in [\"arrest_witnessed_flag\", \"resuscitation_flag\", \"cpr_provided_flag\"]:\n",
    "    events_df[col] = events_df[col].fillna(0).astype(int)\n",
    "\n",
    "print(\"Arrest-related flags merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53f8d511-8e6f-45b1-84d6-f2517dc7360f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eArrest_12 (ROSC): 543it [00:31, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROSC merged. New shape: (297762, 94)\n"
     ]
    }
   ],
   "source": [
    "# ROSC Flag (Return of Spontaneous Circulation)\n",
    "\n",
    "roscs = []\n",
    "rosc_path = \"../data/raw/FACTPCRARRESTROSC.txt\"\n",
    "\n",
    "with open(rosc_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eArrest_12 (ROSC)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eArrest_12\"] = chunk[\"eArrest_12\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            roscs.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "if roscs:\n",
    "    rosc_df = pd.concat(roscs, ignore_index=True).drop_duplicates()\n",
    "    rosc_df[\"rosc_flag\"] = 1\n",
    "    events_df = events_df.merge(rosc_df, on=\"PcrKey\", how=\"left\")\n",
    "    events_df[\"rosc_flag\"] = events_df[\"rosc_flag\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"ROSC merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92d9cdf8-bec5-4192-a216-18a35ada2761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eArrest_17 (Destination Rhythm): 542it [00:30, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination arrest rhythm merged. New shape: (297762, 95)\n"
     ]
    }
   ],
   "source": [
    "# Arrest Rhythm at Destination\n",
    "\n",
    "rhythm_chunks = []\n",
    "rhythm_path = \"../data/raw/FACTPCRARRESTRHYTHMDESTINATION.txt\"\n",
    "\n",
    "with open(rhythm_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eArrest_17 (Destination Rhythm)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eArrest_17\"] = chunk[\"eArrest_17\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            rhythm_chunks.append(filtered[[\"PcrKey\", \"eArrest_17\"]])\n",
    "\n",
    "if rhythm_chunks:\n",
    "    rhythm_df = pd.concat(rhythm_chunks, ignore_index=True)\n",
    "    rhythm_agg = (\n",
    "        rhythm_df.groupby(\"PcrKey\")\n",
    "        .agg(dest_rhythm_count=(\"eArrest_17\", \"nunique\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    events_df = events_df.merge(rhythm_agg, on=\"PcrKey\", how=\"left\")\n",
    "    events_df[\"dest_rhythm_count\"] = events_df[\"dest_rhythm_count\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Destination arrest rhythm merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb154309-1a19-4965-9b88-d16d6998ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ePatient_14 (Race Group): 548it [00:39, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient race info merged. New shape: (297762, 96)\n"
     ]
    }
   ],
   "source": [
    "# Patient Race Group\n",
    "\n",
    "race_chunks = []\n",
    "race_path = \"../data/raw/PCRPATIENTRACEGROUP.txt\"\n",
    "\n",
    "with open(race_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading ePatient_14 (Race Group)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"ePatient_14\"] = chunk[\"ePatient_14\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            race_chunks.append(filtered[[\"PcrKey\", \"ePatient_14\"]])\n",
    "\n",
    "if race_chunks:\n",
    "    race_df = pd.concat(race_chunks, ignore_index=True)\n",
    "    race_agg = (\n",
    "        race_df.groupby(\"PcrKey\")\n",
    "        .agg(race_count=(\"ePatient_14\", \"nunique\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    events_df = events_df.merge(race_agg, on=\"PcrKey\", how=\"left\")\n",
    "    events_df[\"race_count\"] = events_df[\"race_count\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"Patient race info merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d8179f3-799b-4125-9921-dbdf18766474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading eResponse_24 (Response Mode): 612it [00:34, 17.79it/s]\n",
      "Loading eDisposition_18 (Transport Mode): 578it [00:33, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response and transport mode merged. New shape: (297762, 98)\n"
     ]
    }
   ],
   "source": [
    "# Response Mode and Transport Mode\n",
    "\n",
    "response_path = \"../data/raw/FACTPCRADDITIONALRESPONSEMODE.txt\"\n",
    "transport_path = \"../data/raw/FACTPCRADDITIONALTRANSPORTMODE.txt\"\n",
    "\n",
    "# Load response mode (eResponse_24)\n",
    "resp_chunks = []\n",
    "with open(response_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eResponse_24 (Response Mode)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eResponse_24\"] = chunk[\"eResponse_24\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            resp_chunks.append(filtered[[\"PcrKey\", \"eResponse_24\"]])\n",
    "\n",
    "if resp_chunks:\n",
    "    resp_df = pd.concat(resp_chunks, ignore_index=True).drop_duplicates(\"PcrKey\")\n",
    "    events_df = events_df.merge(resp_df, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "# Load transport mode (eDisposition_18)\n",
    "trans_chunks = []\n",
    "with open(transport_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading eDisposition_18 (Transport Mode)\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~'\")\n",
    "        chunk[\"eDisposition_18\"] = chunk[\"eDisposition_18\"].str.strip(\" ~'\")\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(events_df[\"PcrKey\"])]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            trans_chunks.append(filtered[[\"PcrKey\", \"eDisposition_18\"]])\n",
    "\n",
    "if trans_chunks:\n",
    "    trans_df = pd.concat(trans_chunks, ignore_index=True).drop_duplicates(\"PcrKey\")\n",
    "    events_df = events_df.merge(trans_df, on=\"PcrKey\", how=\"left\")\n",
    "\n",
    "print(\"Response and transport mode merged. New shape:\", events_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "218f6d09-2b2a-450b-9db2-568fb28a5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (297762, 98)\n",
      "\n",
      "Missing values per column:\n",
      "eSituation_11           5996\n",
      "eSituation_09           5429\n",
      "eSituation_12           4196\n",
      "assoc_symptom_count     3715\n",
      "assoc_symptom_unique    3715\n",
      "etco2                    145\n",
      "bgl                      145\n",
      "heart_rate               145\n",
      "resp_rate                145\n",
      "systolic_bp              145\n",
      "spo2                     145\n",
      "dtype: int64\n",
      "\n",
      "Unique values per column (non-null):\n",
      "PcrKey                  271206\n",
      "eTimes_05               264238\n",
      "eTimes_06               263980\n",
      "eTimes_03               261992\n",
      "eTimes_13               258661\n",
      "                         ...  \n",
      "any_procedure                1\n",
      "eResponse_09_present         1\n",
      "eResponse_12_present         1\n",
      "eResponse_11_present         1\n",
      "barrier_present              1\n",
      "Length: 98, dtype: int64\n",
      "\n",
      "Value counts for selected columns:\n",
      "\n",
      "--- eOutcome_01 ---\n",
      "eOutcome_01\n",
      "~7701003   ~    247485\n",
      "~7701001   ~     44600\n",
      "~01        ~      2240\n",
      "~30        ~      1450\n",
      "~09        ~       955\n",
      "~07        ~       315\n",
      "~02        ~       288\n",
      "~65        ~       166\n",
      "~21        ~        88\n",
      "~70        ~        49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- eOutcome_02 ---\n",
      "eOutcome_02\n",
      "~7701003   ~    231392\n",
      "~7701001   ~     63256\n",
      "~30        ~      1311\n",
      "~01        ~      1085\n",
      "~07        ~       184\n",
      "~02        ~       128\n",
      "~65        ~       122\n",
      "~06        ~        60\n",
      "~20        ~        55\n",
      "~70        ~        44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- eSituation_11 ---\n",
      "eSituation_11\n",
      "T40.2X4     59794\n",
      "F11         58826\n",
      "F11.9       42575\n",
      "T40.1X4     21306\n",
      "R41.82       9000\n",
      "F11.10       6472\n",
      "NaN          5996\n",
      "T40.1X1A     5034\n",
      "T40.4X4      4745\n",
      "T40.2X1A     4626\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- eSituation_12 ---\n",
      "eSituation_12\n",
      "7701003    142815\n",
      "7701001     31929\n",
      "F11         13594\n",
      "R41.82      10519\n",
      "F11.9        8435\n",
      "T40.2X4      8294\n",
      "Z00.00       6075\n",
      "NaN          4196\n",
      "R53.1        2593\n",
      "R40.20       2487\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- injury_cause_count ---\n",
      "injury_cause_count\n",
      "1    297074\n",
      "2       605\n",
      "3        36\n",
      "5        34\n",
      "4        13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- injury_risk_flag ---\n",
      "injury_risk_flag\n",
      "1    297637\n",
      "0       125\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- trauma_criteria_count ---\n",
      "trauma_criteria_count\n",
      "1    297456\n",
      "2       207\n",
      "3        81\n",
      "0        15\n",
      "4         2\n",
      "5         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- alcohol_drug_use_flag ---\n",
      "alcohol_drug_use_flag\n",
      "1    297762\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final DataFrame Inspection\n",
    "\n",
    "print(\"Final shape:\", events_df.shape)\n",
    "\n",
    "# Count of missing values per column\n",
    "null_counts = events_df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(null_counts[null_counts > 0])\n",
    "\n",
    "# Count of unique values per column (helps spot single-value or ID-like fields)\n",
    "print(\"\\nUnique values per column (non-null):\")\n",
    "print(events_df.nunique().sort_values(ascending=False))\n",
    "\n",
    "# Quick look at distributions of some key columns\n",
    "print(\"\\nValue counts for selected columns:\")\n",
    "for col in [\n",
    "    \"eOutcome_01\", \"eOutcome_02\", \"eMedications_03\", \n",
    "    \"eSituation_11\", \"eSituation_12\", \"injury_cause_count\",\n",
    "    \"injury_risk_flag\", \"trauma_criteria_count\", \"alcohol_drug_use_flag\"\n",
    "]:\n",
    "    if col in events_df.columns:\n",
    "        print(f\"\\n--- {col} ---\")\n",
    "        print(events_df[col].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df85330f-72b4-4c1a-95a4-3bbbb0ab5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PcrKey', 'eDispatch_01', 'eDispatch_02', 'eArrest_14', 'eArrest_01',\n",
      "       'eArrest_02', 'eArrest_05', 'eArrest_07', 'eArrest_11', 'eArrest_16',\n",
      "       'eArrest_18', 'eDisposition_12', 'eDisposition_19', 'eDisposition_16',\n",
      "       'eDisposition_21', 'eDisposition_22', 'eDisposition_23', 'eOutcome_01',\n",
      "       'eOutcome_02', 'ePatient_15', 'ePatient_16', 'ePayment_01',\n",
      "       'ePayment_50', 'eResponse_05', 'eResponse_07', 'eResponse_15',\n",
      "       'eResponse_23', 'eScene_01', 'eScene_06', 'eScene_07', 'eScene_08',\n",
      "       'eScene_09', 'eSituation_02', 'eSituation_07', 'eSituation_08',\n",
      "       'eSituation_13', 'eSituation_01', 'eTimes_01', 'eTimes_03', 'eTimes_05',\n",
      "       'eTimes_06', 'eTimes_07', 'eTimes_09', 'eTimes_11', 'eTimes_12',\n",
      "       'eTimes_13', 'eDisposition_17', 'eSituation_09', 'assoc_symptom_count',\n",
      "       'assoc_symptom_unique', 'eSituation_11', 'eSituation_12',\n",
      "       'injury_cause_count', 'injury_risk_flag', 'trauma_criteria_count',\n",
      "       'barrier_count', 'barrier_unique', 'barrier_present',\n",
      "       'eResponse_08_count', 'eResponse_08_unique', 'eResponse_08_present',\n",
      "       'eResponse_09_count', 'eResponse_09_unique', 'eResponse_09_present',\n",
      "       'eResponse_10_count', 'eResponse_10_unique', 'eResponse_10_present',\n",
      "       'eResponse_11_count', 'eResponse_11_unique', 'eResponse_11_present',\n",
      "       'eResponse_12_count', 'eResponse_12_unique', 'eResponse_12_present',\n",
      "       'eDisposition_20', 'eDisposition_24', 'eDisposition_25', 'heart_rate',\n",
      "       'resp_rate', 'systolic_bp', 'spo2', 'bgl', 'etco2',\n",
      "       'any_med_administered', 'med_count', 'naloxone_administered',\n",
      "       'any_procedure', 'proc_count', 'alcohol_drug_use_flag',\n",
      "       'protocols_used', 'protocol_count', 'arrest_witnessed_flag',\n",
      "       'resuscitation_flag', 'cpr_provided_flag', 'rosc_flag',\n",
      "       'dest_rhythm_count', 'race_count', 'eResponse_24', 'eDisposition_18'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(events_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49f51a21-b458-4583-a541-52d18f26e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../data/interim/opioid_cases_full.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the final dataset\n",
    "events_df.to_csv(\"../data/interim/opioid_cases_full.csv\", index=False)\n",
    "print(\"Saved to ../data/interim/opioid_cases_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9ef76-f027-4d4f-a771-9bf8bb966e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemsis-env",
   "language": "python",
   "name": "nemsis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
