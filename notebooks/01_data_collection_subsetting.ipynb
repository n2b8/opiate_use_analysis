{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2273e787-23cb-4c54-a406-a1f313207ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67456394-cd26-41fc-af0b-399bd364463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Primary Impressions: 530it [00:22, 23.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary impressions matched: 231354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define target ICD-10 prefixes\n",
    "target_prefixes = (\"T40\", \"F11\")\n",
    "\n",
    "# Path to primary impressions file\n",
    "primary_path = \"../data/raw/FACTPCRPRIMARYIMPRESSION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "primary_chunks = []\n",
    "\n",
    "with open(primary_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Primary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_11\"] = chunk[\"eSituation_11\"].str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_11\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk.loc[mask, [\"PcrKey\"]]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            primary_chunks.append(filtered)\n",
    "\n",
    "primary_df = pd.concat(primary_chunks, ignore_index=True)\n",
    "print(\"Primary impressions matched:\", len(primary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d367fc-6922-4a93-8705-3648ae4a8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Secondary Impressions: 544it [00:23, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary impressions matched: 42853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to secondary impressions file\n",
    "secondary_path = \"../data/raw/FACTPCRSECONDARYIMPRESSION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "secondary_chunks = []\n",
    "\n",
    "with open(secondary_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Secondary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_12\"] = chunk[\"eSituation_12\"].str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_12\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk.loc[mask, [\"PcrKey\"]]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            secondary_chunks.append(filtered)\n",
    "\n",
    "secondary_df = pd.concat(secondary_chunks, ignore_index=True)\n",
    "print(\"Secondary impressions matched:\", len(secondary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d3dd6f-00e4-4c9e-b51a-2bf8a2f9b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Primary Impressions: 530it [34:28,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary impressions matched: 231354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define target ICD-10 prefixes\n",
    "target_prefixes = (\"T40\", \"F11\")\n",
    "\n",
    "# Load PRIMARY impressions\n",
    "primary_uri = \"s3://{}/raw-data/FACTPCRPRIMARYIMPRESSION.txt\".format(credentials.BUCKET_NAME)\n",
    "primary_chunks = []\n",
    "\n",
    "with open(primary_uri, transport_params=transport_params) as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000),\n",
    "        desc=\"Processing Primary Impressions\"\n",
    "    ):\n",
    "        # Clean columns\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_11\"] = chunk[\"eSituation_11\"].astype(str).str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].astype(str).str.strip(\" ~\")\n",
    "\n",
    "        # Filter rows with target ICD codes\n",
    "        mask = chunk[\"eSituation_11\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk[mask]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            primary_chunks.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "# Combine all matching rows\n",
    "primary_df = pd.concat(primary_chunks, ignore_index=True)\n",
    "print(\"Primary impressions matched:\", len(primary_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a8a9f6-cb7e-4247-877d-0239b0cf112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Secondary Impressions: 544it [38:04,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary impressions matched: 42853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load SECONDARY impressions\n",
    "secondary_uri = \"s3://{}/raw-data/FACTPCRSECONDARYIMPRESSION.txt\".format(credentials.BUCKET_NAME)\n",
    "secondary_chunks = []\n",
    "\n",
    "with open(secondary_uri, transport_params=transport_params) as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000),\n",
    "        desc=\"Processing Secondary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_12\"] = chunk[\"eSituation_12\"].astype(str).str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].astype(str).str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_12\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk[mask]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            secondary_chunks.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "secondary_df = pd.concat(secondary_chunks, ignore_index=True)\n",
    "print(\"Secondary impressions matched:\", len(secondary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df26d24-82c6-4884-92cb-9ab3bb83dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique opioid-related PcrKeys: 271206\n"
     ]
    }
   ],
   "source": [
    "# Combine primary and secondary\n",
    "opioid_pcr_df = pd.concat([primary_df, secondary_df]).drop_duplicates()\n",
    "\n",
    "print(\"Total unique opioid-related PcrKeys:\", len(opioid_pcr_df))\n",
    "\n",
    "# Convert to set for fast lookup\n",
    "pcr_key_set = set(opioid_pcr_df[\"PcrKey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ae4c5b-f04a-4d95-9fae-0cbbf09183f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Event Records: 542it [04:45,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event records loaded: 271206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to event file\n",
    "event_path = \"../data/raw/pub_pcrevents_cp25.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "event_chunks = []\n",
    "\n",
    "with open(event_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Event Records\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            event_chunks.append(filtered)\n",
    "\n",
    "event_df = pd.concat(event_chunks, ignore_index=True)\n",
    "\n",
    "print(\"Event records loaded:\", len(event_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5fb5b6-6df8-41a1-8a79-08b7040ff065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Vitals: 1648it [05:40,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vitals aggregated: (271071, 64)\n"
     ]
    }
   ],
   "source": [
    "# Path to Vitals file\n",
    "vitals_path = \"../data/raw/FACTPCRVITAL.txt\"\n",
    "\n",
    "# Define vitals columns to extract and aggregate\n",
    "vital_cols = {\n",
    "    \"HeartRate\": \"eVitals_10\",\n",
    "    \"RespRate\": \"eVitals_14\",\n",
    "    \"SystolicBP\": \"eVitals_06\",\n",
    "    \"SpO2\": \"eVitals_12\",\n",
    "    \"BGL\": \"eVitals_18\",\n",
    "    \"ETCO2\": \"eVitals_16\",\n",
    "    \"GCS_Eye\": \"eVitals_19\",\n",
    "    \"GCS_Verbal\": \"eVitals_20\",\n",
    "    \"GCS_Motor\": \"eVitals_21\"\n",
    "}\n",
    "\n",
    "# Prepare chunks\n",
    "vitals_chunks = []\n",
    "\n",
    "with open(vitals_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Vitals\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)].copy()\n",
    "        if not filtered.empty:\n",
    "            for name, col in vital_cols.items():\n",
    "                if col in filtered.columns:\n",
    "                    extracted = filtered[col].str.extract(r\"(\\d+\\.?\\d*)\")[0]\n",
    "                    filtered[name] = pd.to_numeric(extracted, errors=\"coerce\").where(lambda x: x < 1000)\n",
    "            vitals_chunks.append(filtered[[\"PcrKey\"] + list(vital_cols.keys())])\n",
    "\n",
    "# Combine all\n",
    "vitals_df = pd.concat(vitals_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate per PcrKey\n",
    "vitals_agg = (\n",
    "    vitals_df.groupby(\"PcrKey\")[list(vital_cols.keys())]\n",
    "    .agg([\"first\", \"last\", \"min\", \"max\", \"mean\", \"std\", \"count\"])\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "vitals_agg.columns = [\"_\".join(col).strip() for col in vitals_agg.columns.values]\n",
    "vitals_agg = vitals_agg.reset_index()\n",
    "\n",
    "print(\"Vitals aggregated:\", vitals_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573bb529-9762-48d4-aba6-83521c814b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemsis-env",
   "language": "python",
   "name": "nemsis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
