{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2273e787-23cb-4c54-a406-a1f313207ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67456394-cd26-41fc-af0b-399bd364463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Primary Impressions: 530it [00:22, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary impressions matched: 231354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define target ICD-10 prefixes\n",
    "target_prefixes = (\"T40\", \"F11\")\n",
    "\n",
    "# Path to primary impressions file\n",
    "primary_path = \"../data/raw/FACTPCRPRIMARYIMPRESSION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "primary_chunks = []\n",
    "\n",
    "with open(primary_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Primary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_11\"] = chunk[\"eSituation_11\"].str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_11\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk.loc[mask, [\"PcrKey\"]]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            primary_chunks.append(filtered)\n",
    "\n",
    "primary_df = pd.concat(primary_chunks, ignore_index=True)\n",
    "print(\"Primary impressions matched:\", len(primary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d367fc-6922-4a93-8705-3648ae4a8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Secondary Impressions: 544it [00:22, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary impressions matched: 42853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to secondary impressions file\n",
    "secondary_path = \"../data/raw/FACTPCRSECONDARYIMPRESSION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "secondary_chunks = []\n",
    "\n",
    "with open(secondary_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Processing Secondary Impressions\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"eSituation_12\"] = chunk[\"eSituation_12\"].str.strip(\" ~\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        mask = chunk[\"eSituation_12\"].str.startswith(target_prefixes)\n",
    "        filtered = chunk.loc[mask, [\"PcrKey\"]]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            secondary_chunks.append(filtered)\n",
    "\n",
    "secondary_df = pd.concat(secondary_chunks, ignore_index=True)\n",
    "print(\"Secondary impressions matched:\", len(secondary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d3dd6f-00e4-4c9e-b51a-2bf8a2f9b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define target ICD-10 prefixes\n",
    "# target_prefixes = (\"T40\", \"F11\")\n",
    "\n",
    "# # Load PRIMARY impressions\n",
    "# primary_uri = \"s3://{}/raw-data/FACTPCRPRIMARYIMPRESSION.txt\".format(credentials.BUCKET_NAME)\n",
    "# primary_chunks = []\n",
    "\n",
    "# with open(primary_uri, transport_params=transport_params) as f:\n",
    "#     for chunk in tqdm(\n",
    "#         pd.read_csv(f, delimiter=\"|\", chunksize=100_000),\n",
    "#         desc=\"Processing Primary Impressions\"\n",
    "#     ):\n",
    "#         # Clean columns\n",
    "#         chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "#         chunk[\"eSituation_11\"] = chunk[\"eSituation_11\"].astype(str).str.strip(\" ~\")\n",
    "#         chunk[\"PcrKey\"] = chunk[\"PcrKey\"].astype(str).str.strip(\" ~\")\n",
    "\n",
    "#         # Filter rows with target ICD codes\n",
    "#         mask = chunk[\"eSituation_11\"].str.startswith(target_prefixes)\n",
    "#         filtered = chunk[mask]\n",
    "\n",
    "#         if not filtered.empty:\n",
    "#             primary_chunks.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "# # Combine all matching rows\n",
    "# primary_df = pd.concat(primary_chunks, ignore_index=True)\n",
    "# print(\"Primary impressions matched:\", len(primary_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2a8a9f6-cb7e-4247-877d-0239b0cf112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load SECONDARY impressions\n",
    "# secondary_uri = \"s3://{}/raw-data/FACTPCRSECONDARYIMPRESSION.txt\".format(credentials.BUCKET_NAME)\n",
    "# secondary_chunks = []\n",
    "\n",
    "# with open(secondary_uri, transport_params=transport_params) as f:\n",
    "#     for chunk in tqdm(\n",
    "#         pd.read_csv(f, delimiter=\"|\", chunksize=100_000),\n",
    "#         desc=\"Processing Secondary Impressions\"\n",
    "#     ):\n",
    "#         chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "#         chunk[\"eSituation_12\"] = chunk[\"eSituation_12\"].astype(str).str.strip(\" ~\")\n",
    "#         chunk[\"PcrKey\"] = chunk[\"PcrKey\"].astype(str).str.strip(\" ~\")\n",
    "\n",
    "#         mask = chunk[\"eSituation_12\"].str.startswith(target_prefixes)\n",
    "#         filtered = chunk[mask]\n",
    "\n",
    "#         if not filtered.empty:\n",
    "#             secondary_chunks.append(filtered[[\"PcrKey\"]])\n",
    "\n",
    "# secondary_df = pd.concat(secondary_chunks, ignore_index=True)\n",
    "# print(\"Secondary impressions matched:\", len(secondary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df26d24-82c6-4884-92cb-9ab3bb83dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique opioid-related PcrKeys: 271206\n"
     ]
    }
   ],
   "source": [
    "# Combine primary and secondary\n",
    "opioid_pcr_df = pd.concat([primary_df, secondary_df]).drop_duplicates()\n",
    "\n",
    "print(\"Total unique opioid-related PcrKeys:\", len(opioid_pcr_df))\n",
    "\n",
    "# Convert to set for fast lookup\n",
    "pcr_key_set = set(opioid_pcr_df[\"PcrKey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ae4c5b-f04a-4d95-9fae-0cbbf09183f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Event Records: 542it [04:33,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event records loaded: 271206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to event file\n",
    "event_path = \"../data/raw/pub_pcrevents_cp25.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "event_chunks = []\n",
    "\n",
    "with open(event_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Event Records\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)]\n",
    "\n",
    "        if not filtered.empty:\n",
    "            event_chunks.append(filtered)\n",
    "\n",
    "event_df = pd.concat(event_chunks, ignore_index=True)\n",
    "\n",
    "print(\"Event records loaded:\", len(event_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5fb5b6-6df8-41a1-8a79-08b7040ff065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Vitals: 1648it [05:29,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vitals aggregated: (271071, 64)\n"
     ]
    }
   ],
   "source": [
    "# Path to Vitals file\n",
    "vitals_path = \"../data/raw/FACTPCRVITAL.txt\"\n",
    "\n",
    "# Define vitals columns to extract and aggregate\n",
    "vital_cols = {\n",
    "    \"HeartRate\": \"eVitals_10\",\n",
    "    \"RespRate\": \"eVitals_14\",\n",
    "    \"SystolicBP\": \"eVitals_06\",\n",
    "    \"SpO2\": \"eVitals_12\",\n",
    "    \"BGL\": \"eVitals_18\",\n",
    "    \"ETCO2\": \"eVitals_16\",\n",
    "    \"GCS_Eye\": \"eVitals_19\",\n",
    "    \"GCS_Verbal\": \"eVitals_20\",\n",
    "    \"GCS_Motor\": \"eVitals_21\"\n",
    "}\n",
    "\n",
    "# Prepare chunks\n",
    "vitals_chunks = []\n",
    "\n",
    "with open(vitals_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Vitals\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)].copy()\n",
    "        if not filtered.empty:\n",
    "            for name, col in vital_cols.items():\n",
    "                if col in filtered.columns:\n",
    "                    extracted = filtered[col].str.extract(r\"(\\d+\\.?\\d*)\")[0]\n",
    "                    filtered[name] = pd.to_numeric(extracted, errors=\"coerce\").where(lambda x: x < 1000)\n",
    "            vitals_chunks.append(filtered[[\"PcrKey\"] + list(vital_cols.keys())])\n",
    "\n",
    "# Combine all\n",
    "vitals_df = pd.concat(vitals_chunks, ignore_index=True)\n",
    "\n",
    "# Aggregate per PcrKey\n",
    "vitals_agg = (\n",
    "    vitals_df.groupby(\"PcrKey\")[list(vital_cols.keys())]\n",
    "    .agg([\"first\", \"last\", \"min\", \"max\", \"mean\", \"std\", \"count\"])\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "vitals_agg.columns = [\"_\".join(col).strip() for col in vitals_agg.columns.values]\n",
    "vitals_agg = vitals_agg.reset_index()\n",
    "\n",
    "print(\"Vitals aggregated:\", vitals_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573bb529-9762-48d4-aba6-83521c814b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Medications: 628it [01:44,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medications records loaded: 456070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to Medications file\n",
    "meds_path = \"../data/raw/FACTPCRMEDICATION.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "meds_chunks = []\n",
    "\n",
    "with open(meds_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Medications\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "        chunk[\"eMedications_03Descr\"] = chunk[\"eMedications_03Descr\"].str.strip().str.lower()\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)]\n",
    "        if not filtered.empty:\n",
    "            meds_chunks.append(filtered)\n",
    "\n",
    "# Combine all\n",
    "meds_df = pd.concat(meds_chunks, ignore_index=True)\n",
    "\n",
    "print(\"Medications records loaded:\", len(meds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2338e545-3a8d-426c-9e8d-a213e1b65b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medications aggregated: (271206, 7)\n"
     ]
    }
   ],
   "source": [
    "# Flag Naloxone\n",
    "naloxone_flag = meds_df[\"eMedications_03Descr\"].str.contains(\"naloxone|narcan\", na=False)\n",
    "\n",
    "# Aggregate medication info\n",
    "meds_agg = (\n",
    "    meds_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        total_meds=(\"eMedications_03\", \"count\"),\n",
    "        unique_meds=(\"eMedications_03\", \"nunique\"),\n",
    "        naloxone_doses=(\"eMedications_03Descr\", lambda x: x.str.contains(\"naloxone|narcan\", na=False).sum()),\n",
    "        naloxone_flag=(\"eMedications_03Descr\", lambda x: x.str.contains(\"naloxone|narcan\", na=False).any()),\n",
    "        first_route=(\"eMedications_07\", \"first\"),\n",
    "        first_response=(\"eMedications_10\", \"first\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"Medications aggregated:\", meds_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e52deeba-5bdf-4ed7-be91-06c0c7523582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Procedures: 934it [01:50,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procedures records loaded: 587755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to Procedures file\n",
    "proc_path = \"../data/raw/FACTPCRPROCEDURE.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "proc_chunks = []\n",
    "\n",
    "with open(proc_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading Procedures\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)]\n",
    "        if not filtered.empty:\n",
    "            proc_chunks.append(filtered)\n",
    "\n",
    "# Combine all\n",
    "proc_df = pd.concat(proc_chunks, ignore_index=True)\n",
    "\n",
    "print(\"Procedures records loaded:\", len(proc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b630d80f-d28f-4696-96e4-5fdb2b0b252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procedures aggregated: (271206, 6)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate procedures per PcrKey\n",
    "proc_agg = (\n",
    "    proc_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        procedure_count=(\"eProcedures_03\", \"count\"),\n",
    "        unique_procedures=(\"eProcedures_03\", \"nunique\"),\n",
    "        first_procedure=(\"eProcedures_03\", \"first\"),\n",
    "        all_procedures=(\"eProcedures_03\", lambda x: list(x.dropna()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Optionally stringify list for easier storage\n",
    "proc_agg[\"all_procedures_str\"] = proc_agg[\"all_procedures\"].apply(lambda x: \"|\".join(x) if x else \"\")\n",
    "\n",
    "print(\"Procedures aggregated:\", proc_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10e34f16-38cb-4411-afcf-4abba7e21559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading CPR Records: 546it [00:34, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPR records loaded: 275322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to CPR records\n",
    "cpr_path = \"../data/raw/FACTPCRARRESTCPRPROVIDED.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "cpr_chunks = []\n",
    "\n",
    "with open(cpr_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading CPR Records\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)]\n",
    "        if not filtered.empty:\n",
    "            cpr_chunks.append(filtered)\n",
    "\n",
    "cpr_df = pd.concat(cpr_chunks, ignore_index=True)\n",
    "\n",
    "print(\"CPR records loaded:\", len(cpr_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddafba95-d190-4349-924a-91adfecc02d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPR aggregated: (271206, 4)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate CPR info\n",
    "cpr_agg = (\n",
    "    cpr_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        cpr_given=(\"eArrest_09\", lambda x: True),\n",
    "        bystander_cpr=(\"eArrest_09\", lambda x: x.str.contains(\"BYSTANDER\", case=False, na=False).any()),\n",
    "        ems_cpr=(\"eArrest_09\", lambda x: x.str.contains(\"EMS|CREW|PROVIDER\", case=False, na=False).any())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"CPR aggregated:\", cpr_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9445c5cf-04dd-42aa-8adf-628c21fabebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ROSC Records: 543it [00:35, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROSC records loaded: 271712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to ROSC records\n",
    "rosc_path = \"../data/raw/FACTPCRARRESTROSC.txt\"\n",
    "\n",
    "# Prepare chunks\n",
    "rosc_chunks = []\n",
    "\n",
    "with open(rosc_path, \"r\") as f:\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(f, delimiter=\"|\", chunksize=100_000, dtype=str),\n",
    "        desc=\"Loading ROSC Records\"\n",
    "    ):\n",
    "        chunk.columns = chunk.columns.str.strip(\" ~'\")\n",
    "        chunk[\"PcrKey\"] = chunk[\"PcrKey\"].str.strip(\" ~\")\n",
    "\n",
    "        filtered = chunk[chunk[\"PcrKey\"].isin(pcr_key_set)]\n",
    "        if not filtered.empty:\n",
    "            rosc_chunks.append(filtered)\n",
    "\n",
    "rosc_df = pd.concat(rosc_chunks, ignore_index=True)\n",
    "\n",
    "print(\"ROSC records loaded:\", len(rosc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c1db0a-badb-4f3a-a9ea-2bc5f2cf3935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROSC aggregated: (271206, 2)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate ROSC flag\n",
    "rosc_agg = (\n",
    "    rosc_df.groupby(\"PcrKey\")\n",
    "    .agg(\n",
    "        rosc_achieved=(\"eArrest_12\", lambda x: x.str.contains(\"YES\", case=False, na=False).any())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"ROSC aggregated:\", rosc_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3b1a3-faf6-4545-967e-51d5c8c3f0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemsis-env",
   "language": "python",
   "name": "nemsis-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
